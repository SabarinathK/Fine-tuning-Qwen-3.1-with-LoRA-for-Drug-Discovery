{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrqVEwz_hSL4"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U transformers accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kXjtjFKhroc"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name=\"unsloth/Qwen3-1.7B-bnb-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ck586aRKi8cS"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTmcx6BGlw1j",
    "outputId": "dede86ed-17c1-4ef7-bf46-238a4525176c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: The **TP53** gene is a critical tumor suppressor gene that plays a central role in maintaining genomic stability, regulating the cell cycle, and initiating apoptosis in response to DNA damage. Its dysfunction is a hallmark of many cancers, making it a pivotal therapeutic target. Below is a structured explanation of why TP53 is an important therapeutic target:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Role of TP53 in Cell Cycle and Apoptosis**\n",
      "- **Cell Cycle Regulation**: TP53 acts as a \"guardian of the genome\" by monitoring DNA integrity. When DNA damage occurs, TP53 activates the **p53 pathway**, which halts the cell cycle (via **G1 checkpoint**) and promotes DNA repair. If the damage is irreparable, TP53 triggers **apoptosis** (programmed cell death) to eliminate damaged cells.\n",
      "- **Apoptosis Induction**: TP53 is a key mediator of apoptosis. Mutant TP53 (e.g., in *TP53* mutations) fails to induce apoptosis, leading to uncontrolled cell proliferation and cancer.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. TP53 Mutations in Cancer**\n",
      "- **Common Mutations**: TP53 mutations are found in ~50% of all human cancers (e.g., lung, breast, liver, colorectal cancers). These mutations include:\n",
      "  - **Loss-of-function**: Inactive TP53 (e.g., in *TP53* mutations).\n",
      "  - **Gain-of-function**: Rare, but possible in some cancers (e.g., in *TP53* mutations with altered activity).\n",
      "- **Cancer Development**: TP53 mutations lead to genomic instability, uncontrolled cell division, and resistance to cell death, driving tumor progression.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Therapeutic Targets for TP53**\n",
      "- **Targeting TP53 Pathway**:\n",
      "  - **Apoptosis Induction**: Drugs that reactivate TP53 (e.g., **TP53 agonists**) or induce apoptosis in TP53-defective cancer cells.\n",
      "  - **Cell Cycle Arrest**: Inhibiting TP53's downstream effects (e.g., **p21**, **Bax**, **caspases**) to block cell cycle progression.\n",
      "- **Anti-Cancer Therapies**:\n",
      "  - **Targeted Therapies**: Drugs like **PD-115** (a TP53 agonist) or **TP53 inhibitors** (e.g., **GSK2262228**) aim to restore TP53 function or inhibit mutant TP53.\n",
      "  - **Combination Therapies**: Pairing TP53-targeted drugs with conventional therapies (e.g., chemotherapy, radiation) to enhance efficacy.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Challenges and Considerations**\n",
      "- **Resistance**: TP53 mutations can lead to resistance to therapies targeting the pathway (e.g., **TP53-null** cancers).\n",
      "- **Off-Target Effects**: Inhibiting TP53 may affect normal cells with TP53 mutations, causing toxicity.\n",
      "- **Biomarker Development**: Identifying TP53 mutation profiles (e.g., wild-type vs. mutant) to tailor therapies.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Clinical Relevance**\n",
      "- **Biomarker for Therapy**: TP53 mutations are used to guide treatment choices (e.g., in **TP53** mutations, TP53 agonists are more effective).\n",
      "- **Emerging Therapies**: Research into TP53's role in DNA repair (e.g., **PARP** inhibitors) and cell cycle checkpoints (e.g., **CDK** inhibitors) is expanding therapeutic options.\n",
      "\n",
      "---\n",
      "\n",
      "### **Conclusion**\n",
      "TP53 is a critical therapeutic target due to its central role in preventing cancer by regulating the cell cycle and apoptosis. Its dysfunction is a major driver of tumor development, and targeting it offers potential for broad-spectrum cancer therapy. However, challenges in targeting TP53 (e.g., resistance, toxicity) necessitate careful development of therapies that address its complex biology. Future research will likely focus on refining TP53-targeted drugs and biomarkers to improve therapeutic outcomes. \n",
      "\n",
      "This makes TP53 a cornerstone in oncology, with significant implications for both treatment strategies and cancer prevention.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Why is TP53 an important therapeutic target?\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "# print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "ed88e73e59124b869269d957b0db2cd3",
      "6abfba7900f0458f896e572824f8d035",
      "a573c8ca7b2743e680b0351e98c412c1",
      "70245a5fe64f4c5b9b159218ec56153d",
      "cd6854e632a24626a7e3f40aebe4767b",
      "e6378c44cfe44778bac8894504c6f4ec",
      "0b33102e78d14477914fe88c38794c11",
      "d90415dcd3844c4496e4b18346d7c1ce",
      "617c94d9712e45559880ef78454bdbbf",
      "73bb7e3419db4130b150e75bd6fb53b7",
      "6b89dfc512574f6cbb626d58390b50fb"
     ]
    },
    "id": "2qeU3BROqi71",
    "outputId": "9f298932-2e8a-485f-e518-1d1d0385ee39"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed88e73e59124b869269d957b0db2cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_data = load_dataset(\"json\", data_files=\"/content/drug_target_discovery_200.json\")\n",
    "print(raw_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NJUHR-wroDa",
    "outputId": "17dee16c-8584-4304-d1e1-443f68c19e83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Describe how HER2 contributes to cellular signaling in disease.',\n",
       " 'completion': 'HER2 is a growth factor receptor amplified in breast cancers; targeted by trastuzumab.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "raw_data[\"train\"][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "afd7c00c8d69458188e5b7706cba3486",
      "eaa9df50696f4d82a2b5dbb1aef491da",
      "6a956759ce2e4f8798eca7f4c77ce685",
      "fe1e660063754a6e8a25e11d9ab7009f",
      "b3bc580b897d4540a9948fd6b9e8f86e",
      "f438233c47cb4a4cafbdfc4e81de0a9a",
      "2590458ca1d140049ffd7acbfe1937dd",
      "fc60469ba6024207979c1056abaf7a54",
      "43abd35d87ad47df965bb746cbf42cf9",
      "f59206a876fe44bc93af7a89dc857b97",
      "aa4d82bb7f374526a66bcba91a8928e8"
     ]
    },
    "id": "C6jhGvE1r0NX",
    "outputId": "f0b9e96a-c00f-449d-b511-deb20ca8b568"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd7c00c8d69458188e5b7706cba3486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name\n",
    ")\n",
    "\n",
    "def preprocess(sample):\n",
    "    sample = sample[\"prompt\"] + \"\\n\" + sample[\"completion\"]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        sample,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "data = raw_data.map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55WdELcNr7KL",
    "outputId": "a21f7e59-fef2-41c8-b352-e2b6df62ee40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Describe how HER2 contributes to cellular signaling in disease.', 'completion': 'HER2 is a growth factor receptor amplified in breast cancers; targeted by trastuzumab.', 'input_ids': [151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 74785, 1246, 15645, 17, 42972, 311, 34593, 41980, 304, 8457, 624, 3012, 17, 374, 264, 6513, 8168, 34168, 82498, 304, 17216, 50323, 26, 17112, 553, 489, 559, 5197, 372, 370, 13], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 151654, 74785, 1246, 15645, 17, 42972, 311, 34593, 41980, 304, 8457, 624, 3012, 17, 374, 264, 6513, 8168, 34168, 82498, 304, 17216, 50323, 26, 17112, 553, 489, 559, 5197, 372, 370, 13]}\n"
     ]
    }
   ],
   "source": [
    "print(data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3DFD3VNer_P7",
    "outputId": "f1952a0c-e2dc-4198-a781-5d5556190e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen3ForCausalLM(\n",
       "      (model): Qwen3Model(\n",
       "        (embed_tokens): Embedding(151936, 2048, padding_idx=151654)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=6144, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=6144, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=6144, out_features=2048, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "        (rotary_emb): Qwen3RotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype = torch.float16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type = TaskType.CAUSAL_LM,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Explicitly move the model to the CUDA device\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "jAPyk-4jsKpE",
    "outputId": "dc1096d1-682b-4f3c-8c01-58e938101c82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 11:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.634900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>13.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>13.349000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>13.349100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>13.348100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>13.347400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>13.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>13.346300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>13.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>13.345500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=13.377767944335938, metrics={'train_runtime': 668.9913, 'train_samples_per_second': 2.99, 'train_steps_per_second': 0.374, 'total_flos': 2168377049088000.0, 'train_loss': 13.377767944335938, 'epoch': 10.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    logging_steps=25,\n",
    "    report_to=\"none\" # Disable wandb logging\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data[\"train\"]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnG-dsdWuZOa",
    "outputId": "c8c8347f-2d59-42d8-9639-333b6a5b2222"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Qwen-1.7B-MedQA-LoRA/tokenizer_config.json',\n",
       " 'Qwen-1.7B-MedQA-LoRA/special_tokens_map.json',\n",
       " 'Qwen-1.7B-MedQA-LoRA/chat_template.jinja',\n",
       " 'Qwen-1.7B-MedQA-LoRA/vocab.json',\n",
       " 'Qwen-1.7B-MedQA-LoRA/merges.txt',\n",
       " 'Qwen-1.7B-MedQA-LoRA/added_tokens.json',\n",
       " 'Qwen-1.7B-MedQA-LoRA/tokenizer.json')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"Qwen-1.7B-MedQA-LoRA\")\n",
    "tokenizer.save_pretrained(\"Qwen-1.7B-MedQA-LoRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWPEVTwKx3Dd"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "path = \"/content/Qwen-1.7B-MedQA-LoRA\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(path)\n",
    "base = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n",
    "model = PeftModel.from_pretrained(base, path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xexyJSdoyDXn",
    "outputId": "ae0cf163-4692-436f-a6ae-14ef6e85b44a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is TP53 an important therapeutic target? TP53 is a tumor suppressor protein that regulates DNA repair and apoptosis; mutations lead to uncontrolled cell growth. BRAF is a MAPK pathway kinase; V600E mutation causes melanoma and other cancers. TP53 is a key player in apoptosis and DNA repair; mutations lead to uncontrolled cell growth.\n",
      "TP53 is a critical tumor suppressor protein that regulates apoptosis and DNA repair. Mutations lead to uncontrolled cell growth and resistance to apoptosis. BRAF is\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer( \"Why is TP53 an important therapeutic target?\", return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    max_new_tokens=100 # Reduced for faster generation, adjust as needed\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hE4WlWSHy3Ye"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c286a0b"
   },
   "source": [
    "## Install huggingface hub\n",
    "\n",
    "### Subtask:\n",
    "Install the necessary library to interact with the Hugging Face Hub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1921039d"
   },
   "source": [
    "**Reasoning**:\n",
    "The subtask is to install the `huggingface_hub` library. The `pip install` command is used to install Python packages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254ca28b"
   },
   "outputs": [],
   "source": [
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVclWSb39nqU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4906e31f"
   },
   "source": [
    "## Login to hugging face hub\n",
    "\n",
    "### Subtask:\n",
    "Authenticate with your Hugging Face account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ad329d8"
   },
   "source": [
    "**Reasoning**:\n",
    "Import the `notebook_login` function and call it to authenticate with Hugging Face.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "81b8f806ca2b4fb59a4694b7ce884cb5",
      "018e396930374a17bfe97acfa424b562",
      "dc5f96e568244b1fa58432be10f32b0e",
      "03b6d946bc4b4f588b01704db640c5e0",
      "02e7eb3fc0c64f7a98a23651f56ce3aa",
      "54bfcb487a044b30a0d391849f540ff8",
      "2e4a5a08d46d42f8a52ccd43741dedf1",
      "e7bfca04b948448293c94dca3612baf4",
      "b0a7e4f0c09a4bdbafe32323505c5ec2",
      "5dfb4585ed3c446a8e948dd2c583ac19",
      "7b7a5f7d974f48f4992de03caacf3306",
      "91127ccb6b4842889beee7e22eff9eb1",
      "b4ba94ff3ad942edbb274371256c4e3d",
      "7f94b8c35e1445c1896c63034649aa74",
      "e80ca04a0cee406c89e1be08f1165f68",
      "9c81053d084a4a44b165d86fecda39a4",
      "863e57b98ad84574bc893e24ddcb35ae",
      "d5a40ea8958b4607841ec571498e1158",
      "5f3bc88355d84dd08d16691c209918c4",
      "8e5820bb3e0947d9b9cf6699ae99fe6e"
     ]
    },
    "id": "1ebeff46",
    "outputId": "78cf2f92-5972-472f-fe91-98d7c3808580"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b8f806ca2b4fb59a4694b7ce884cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e8cfc99"
   },
   "source": [
    "## Push model and tokenizer\n",
    "\n",
    "### Subtask:\n",
    "Push the fine-tuned model and tokenizer to the Hugging Face Hub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a12f9be"
   },
   "source": [
    "**Reasoning**:\n",
    "Push the fine-tuned model and tokenizer to the Hugging Face Hub using the `push_to_hub` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328,
     "referenced_widgets": [
      "3627c74d664049d6a9c4339a59293eb1",
      "079e78a3c08541c58ce6c53d4d18008c",
      "90718fddd4f1496da9248a32b742f202",
      "e857c0a2537348b0adbe8f29e52de335",
      "3e569b9d48c2434788335f7095785de9",
      "9dbd70a9ad5d4b8496bb0f3753117d49",
      "122f4e68c96c461093df9ee32bb68be8",
      "c7f4c12b956f4535afab8ee479812f29",
      "c684b9ecd4534a3da1212b34ffcf8667",
      "1c4f7adafb0e489aa273a1629875ee70",
      "58887b66cc5d4569b8450b0684c52342",
      "401c0180e66949adb919ee9e8af3fd12",
      "fe63b97688d8486abca1b9d3c3d52db5",
      "38c6e5e7e15e460d919d1b2ba2b5fc65",
      "9c0f98d225f14b88817a0c13c99a4374",
      "3859c390b837476d80a59fb180505dac",
      "b5ed26c0d7bb4d78a6960366bd86f1e0",
      "3f9e164bb3b34fa2a77636134ce70124",
      "235b7628e527450f8ff0cc15dd42d970",
      "9385650d6ce54d03a4bfb2ed20ef33c2",
      "8f4eaf4a90ef42ebad31fdc4554b9108",
      "35c92436037e48f092fcafeffc9da3a7",
      "90503eb687f741eb942df57a426ac76e",
      "7b2a671bc33e4766be06c01f6c1f5295",
      "b78185f5a07a46c5a23753dc33f5269b",
      "0b1fa8375b36481281d7aaa342f201da",
      "4a63c054212b4832939b2bf90406ed7e",
      "a6029b298cdf42f88bfd6a795f04e4e9",
      "0c532a8a045b42bfae4c3c7c0fb62acc",
      "b5910675ae1b4d889fae14dfd5c7702c",
      "7a758417ad474e3280a36d9d1d6a59ea",
      "6c4f2e69b6384871a3b0f53e1312e4a0",
      "df865d5a48744ce08c8267fd4d479d23",
      "26794f6c73dc40de896a0b171090aeb0",
      "7f09eba0e46a4c56919c24ca94f0a729",
      "ede50471fbf54b5ab3fe6c22559e9ce5",
      "79773bf60f774eec90abbe148630d3b2",
      "8756b4b012554b9c802fccdc897a120e",
      "20be4c92f671416aa2de29f8837a14db",
      "242bcac702624052b42089febd85fe8b",
      "cd407e8cec52479e8f428d915f319041",
      "5b03e6eff64e410ab35b7a4939245693",
      "f3e2044dc9044b8998777d49cad86afa",
      "ab201ac95fae4daeb31d27473fdfb01d",
      "274d2043a99e418ebf199ffbb441fa08",
      "05c128c0207c450c92070df74bdc727d",
      "cafe2079ff614daeb899aba755699f54",
      "cbfe8ad13aad42e48512e016deb59a1c",
      "c93a62a0039a421ea9c73dbc6263fb68",
      "4ba2d580ea6c41afb5c166b2c295c18e",
      "1a21bf28df0b4b90bc4e6c62d695e92f",
      "9dbfa79091324bfe8ccef18ad9d3ef6a",
      "0d8177c6ad5c4824a145c1186cc9998c",
      "d66de7f99f7c44d6ac867cc9b9aaecfe",
      "abe5ba286c664c42bc3fa41afa945ae8",
      "7b4c8c20ba734caabaa7a882db3b0523",
      "a666a54ddddb400f8567129675634c9b",
      "dc25d4aeb7c04510b1eb86f649d548cf",
      "66a9cea90a7a45e6a81b0c6c2a838134",
      "daff5abb9d7a4fd2ba9dea7723bf91fe",
      "fc26893e8dc648dd99e8f4e26668cadf",
      "2a2ea9a0e3bf418681211f4fb3d39b1d",
      "890611f3a82c4c50bedb5f16d17357c5",
      "e06bfbb240d848eeb66087fc34e619bf",
      "5ed89e9eeb2e49eb876f35e2d243d19c",
      "8446d6482cd04013b65d9c55029dd724",
      "49b73daf19f94ef2afbeaf7769f62062",
      "15bebdad3e3f48b89560b523ffa9fb90",
      "3a617dda5d4242519416c2b7b8646aa6",
      "04f7dd9ecf73480384cddd990ced898f",
      "e4023e3fef334900a235bbe6938265b7",
      "4e23ef54242c4a81997c509bf34f0b92",
      "2ffb5133511248be98e1a6f79780bc14",
      "1f095adc68f04977a5a59f2afe2bcb63",
      "62602cd47d424207962824b619682c26",
      "4ef23fc509e649b7afcb0fb396b8fb7b",
      "efd5d4e65d6443f7b4a7db4bd4fcb445"
     ]
    },
    "id": "0bce0a5b",
    "outputId": "6de75ef7-ed86-453b-8a35-a14b575c3d8d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3627c74d664049d6a9c4339a59293eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401c0180e66949adb919ee9e8af3fd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90503eb687f741eb942df57a426ac76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors:   6%|6         |  564kB / 9.20MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26794f6c73dc40de896a0b171090aeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274d2043a99e418ebf199ffbb441fa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4c8c20ba734caabaa7a882db3b0523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b73daf19f94ef2afbeaf7769f62062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...MedQA-LoRA/tokenizer.json:   0%|          | 28.3kB / 11.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Sabarinath-K/Qwen-1.7B-MedQA-LoRA/commit/903e939e35e5ffd29830098541ad029a9843fedf', commit_message='Upload tokenizer', commit_description='', oid='903e939e35e5ffd29830098541ad029a9843fedf', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Sabarinath-K/Qwen-1.7B-MedQA-LoRA', endpoint='https://huggingface.co', repo_type='model', repo_id='Sabarinath-K/Qwen-1.7B-MedQA-LoRA'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"Qwen-1.7B-MedQA-LoRA\")\n",
    "tokenizer.push_to_hub(\"Qwen-1.7B-MedQA-LoRA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9b91240"
   },
   "source": [
    "**Reasoning**:\n",
    "The previous attempt to push to the hub failed due to an authentication error. I will try logging in again to ensure proper authentication before attempting to push the model and tokenizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "3b610f87a09248fe9b141d8897b18b7a",
      "5b6b8312403148f080ce24c2dc666536",
      "fca8b86f0201417eab8f8b89e3ab7d25",
      "0fcd3468a3334d28ac9abb4157eb23e8",
      "80a22ea6aea84a04b764ab18e1429fa8",
      "e00c1a9016a44458be30534377973d6a",
      "225e468e315a43999b693e84aca41204",
      "4b9eca6acb2c44428cabccb86713a47b",
      "b07fae8f20a641709b275d0d96f5b17e",
      "af6fa6c3ca2045ef93c362ef4d366601",
      "cdf5d1bfaf544fbebbbc3391b4950d22",
      "b8506e06ca77485fa4c34a7a7b4d3e19",
      "16b2fe60b0434cd5b422a883cdf2af46",
      "09f81838590b44509a167eb7d6547619",
      "32e702e663bc4426817f99e671c427b5",
      "db7cfb758e2d48f79046f6790914c90c",
      "f785fb9c339c4aa89c259387297ba4ac",
      "e0954bfb807447e89fd943dbdcbf4ca1",
      "c32aaf5cd557420c8d52fa669c7a89dc",
      "636943703bd943bcb5c1175635deb017"
     ]
    },
    "id": "F0bQ15m39zzl",
    "outputId": "fa8d3931-2dbe-43b9-8e4b-11f03c94c81c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b610f87a09248fe9b141d8897b18b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76123b3a"
   },
   "source": [
    "**Reasoning**:\n",
    "After re-authenticating, I will attempt to push the fine-tuned model and tokenizer to the Hugging Face Hub again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "3c687ca49cce4282937502025b11f901",
      "ab18476d418c4e7c812bd84deedb5294",
      "d89f532e61ec4d6d93a302d2b6565f14",
      "dc53c1a9ce4a40f7bf86340ded7bb39b",
      "c0fa0be2e4024381a918bc0688877131",
      "122c3ea63db64e42a77658745d6676c8",
      "f3011ce58e4c463ab4a929e07211dbc6",
      "db3500436087457fa80cf2b27dfa41da",
      "c20ea4d54c484b369e91af9234f7fcbd",
      "9a03820398444c2e97fcb5ec11977795",
      "277d0a3e11684159aec5ce3e0447def9",
      "652b309dd88d485896eed8187d97b112",
      "fbb59dd5b22d4c9fa97f3d1c39e7477c",
      "36baed78d7c34bc4b502e532098d8bca",
      "ef7b9a414cae42d7b0a7b52688bef848",
      "94154b4a2d2346f4b386c35788df9998",
      "cb11bd05b43846a6a919e151ac66596c",
      "0d5a7707872c41a09384528cb11ba428",
      "b302240d98714c3e88599011c1e08a73",
      "2d37830cc0914fad9f97da63bd706e79",
      "10a597bffdaf4b279779be46dfc66595",
      "3fbf668da571457b9eb69b3d3f19ce65",
      "303643e5587249e8b1fd4752368b4e0c",
      "dbc12d328ed94cb9be8904c12e0e18c9",
      "15f3d7959ec649e3b0f65c23f8efab65",
      "f228ff01e4924d689addda052f5c2f7c",
      "9d2c77b820c64fcea5bb095c0eaf747a",
      "76c75f9f9bd940be91c3367b7e3133bd",
      "fd8e4eff0403450f9f7d9d1e4cca0653",
      "e54fc63eb5534ba9a073dabddbd25df1",
      "236fc8f2d5d04ae09166a22ed259c288",
      "e0acd1116e60433d981f8996a0ffe2d8",
      "69ff1e6136984608854b12bed6542742",
      "84ac7f2ec898432b9e9b0d7586e58413",
      "971736384927484b91ac6dcaabc2b834",
      "1ece546e0fa84eea9e158860831c6bc3",
      "3cc4ef37312e4b018bad50c47307fda9",
      "7e4d2127fa174153874e4f12c35b0088",
      "10eea7ef1c734b6f8d38d05118d2c234",
      "d121416337154056bdf8461f2de48e0d",
      "ee4c704a195743ad82f9be9087093d37",
      "a577bc479e754916abb501d45bda611e",
      "9c728c6396cd4dd7924fae768871591a",
      "824cefda19f74d6c966c82ce4a7c4edb",
      "fc56a800518a428f9e3a4482559d4f48",
      "162b25356aaf467b9add43c338f93152",
      "9f70691903314808b27b23aaeac2920f",
      "6c8e4d597c2843eeace2b19882641b11",
      "77af5a15b48046f39b01cd140e657464",
      "1ec77cfec8de4f75b94ca3975f8de92b",
      "142fb0056e924714a1aed5dfe58a19fe",
      "e7bac6d1d0644e59a3aca05b44bfcfc6",
      "b4fed1fa7f5f404abb365d9c2aaffc1a",
      "754efcfeec5f46bdbd8c092554a09521",
      "8c322bad833240619f7258005f5c7bed",
      "b155efb002ce49959ed0b588b8da2ea0",
      "cf715b9f2b9a459d9bf78e9bd66ee2fc",
      "d20d930c7ec54ecb8065b0a53eba7706",
      "72d72989d49d4c61b4deef36ee5bf3af",
      "fe86eda62382432d892133445b13a099",
      "9f362e6f7c5f4c43a35750e4d7c4078f",
      "a0837a2b90454eaca5a22e1c1457caac",
      "a6c6cb964fd447dcb319d4c7a28375a0",
      "5222bca26a864d7a8965f411bd709fbb",
      "b497478d8d9d4e8d86eb0da7ce60e577",
      "5f223497bfda4376bded17500e282d12",
      "1c59e06f58084e548b35cb1a7860f107",
      "ec81c7c031b148708e92fb04abb12743",
      "ae05842b389a4e14af0f5807c22b0158",
      "d1f86109c2f841b9b36132552d3fd680",
      "a6fa0a594eb6443696ca654e3003e4e9",
      "c89d0cd1bd2148aba32a837ca770b5df",
      "7f7b8a8a427449118649412093b960b8",
      "72992a7333264b9fa9e91c952084ffcc",
      "e4167152e6ba40df961d4d12cd9c75ed",
      "a8e3646e785e4a48b206f464a78da3d1",
      "589dfea3717d431587dface0360accfb"
     ]
    },
    "id": "2b87d1fe",
    "outputId": "fa024736-0728-459a-db0d-71ab37bc3139"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c687ca49cce4282937502025b11f901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652b309dd88d485896eed8187d97b112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303643e5587249e8b1fd4752368b4e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors: 100%|##########| 9.20MB / 9.20MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ac7f2ec898432b9e9b0d7586e58413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors: 100%|##########| 9.20MB / 9.20MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc56a800518a428f9e3a4482559d4f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b155efb002ce49959ed0b588b8da2ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c59e06f58084e548b35cb1a7860f107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...MedQA-LoRA/tokenizer.json: 100%|##########| 11.4MB / 11.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Sabarinath-K/Qwen-1.7B-MedQA-LoRA/commit/903e939e35e5ffd29830098541ad029a9843fedf', commit_message='Upload tokenizer', commit_description='', oid='903e939e35e5ffd29830098541ad029a9843fedf', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Sabarinath-K/Qwen-1.7B-MedQA-LoRA', endpoint='https://huggingface.co', repo_type='model', repo_id='Sabarinath-K/Qwen-1.7B-MedQA-LoRA'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"Qwen-1.7B-MedQA-LoRA\")\n",
    "tokenizer.push_to_hub(\"Qwen-1.7B-MedQA-LoRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "E_QveShG-elg",
    "outputId": "7fbd081a-426e-46e9-d86b-38d172bcafa2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://ab6c09b7dee14b959e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ab6c09b7dee14b959e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "model_id = \"Sabarinath-K/Qwen-1.7B-MedQA-LoRA\"\n",
    "\n",
    "classifier = pipeline(\"text-generation\", model=model_id)\n",
    "\n",
    "def inference(text):\n",
    "    output = classifier(text)[0]\n",
    "    print(\"Classifier output:\", output) # Add this line to inspect the output\n",
    "    return output['generated_text']\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=inference,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Qwen-1.7B-MedQA-LoRA\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3Zs4QxJFf0i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
